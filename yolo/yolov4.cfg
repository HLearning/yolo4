batch=64               # 一次性训练样本的数量， 和tf里面的不一样， 这里表示64张样本更新一次参数
subdivisions=8         # batch/subdivisions作为一次性送入训练器的样本数量，如果内存不够大，将batch分割为subdivisions个子batch
width=608              # 图片的宽
height=608             # 图片的高
channels=3             # 图片的通道
momentum=0.949         # 动量 DeepLearning1中最优化方法中的动量参数，这个值影响着梯度下降到最优值得速度
decay=0.0005           # 权重衰减正则项，防止过拟合
angle=0                # 数据增强参数，通过旋转角度来生成更多训练样本
saturation = 1.5       # 数据增强参数，通过调整饱和度来生成更多训练样本
exposure = 1.5         # 数据增强参数，通过调整曝光量来生成更多训练样本
hue=.1                 # 数据增强参数，通过调整色调来生成更多训练样本
learning_rate=0.0013   # 学习率
burn_in=1000           # 在迭代次数小于burn_in时，其学习率的更新有一种方式，大于burn_in时，才采用policy的更新方式
max_batches = 500500   # 训练达到max_batches后停止学习
policy=steps           # 这个是学习率调整的策略，有policy：constant, steps, exp, poly, step, sig, RANDOM，constant等方式
steps=400000,450000    # 训练步长， 控制学习率衰减， 和scales一起使用，  learning_rate = learning_rate × scales
scales=.1,.1           # 学习率衰减的系数
cutmix=1               # cutmix
mosaic=1               # 马赛克
mask = 0,1,2           # anchor_mask
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401   # 608对应的anchors
classes=80             # coco的类别
num=9                  # anchors的数量
jitter=.3              # 抖动
ignore_thresh = .7     # 参与计算的loss的框与真实框的IOU阈值大小
truth_thresh = 1
scale_x_y = 1.2
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou          # 使用ciou_loss
nms_kind=greedynms
beta_nms=0.6
max_delta=5





